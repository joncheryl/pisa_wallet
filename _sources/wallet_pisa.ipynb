{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad04896",
   "metadata": {},
   "source": [
    "# PISA vs Wallets vs Survey vs Social Capital measures.\n",
    "In Dave Tannenbaum's paper, it is shown that \n",
    "- wallet report rates are, in fact, correlated with survey measures of social capital, showing that survey data contains useful information. \n",
    "- wallet report rates serve as a predictor in models of \"Economic and Institutional Performance\", suggesting that social capital as measured by wallet report rates can \"explain variation in economic development\".\n",
    "\n",
    "I was curious how education data would relate to these results. I found some international measures of educational achievement here: (reading data on page 54/55 of report https://www.oecd.org/en/publications/pisa-2022-results-volume-i_53f23881-en.html. I mostly just used the 2022 data which is notably missing observations for China, Ghana, India, Kenya, Russia, and South Africa. The 2018 data has data for China and Russia, although China is an extreme outlier (this probably deserves a note in an appendix) with the highest education scores and some of the lowest wallet reporting rates. It is noted in the Tannenbaum paper that China was a special case for wallet reporting rates. It should also be noted that Asian countries are not well represented in the wallet data set. The only east Asian countries are China, Malaysia, Thailand, and Indonesia and China is significantly different from the others.\n",
    "\n",
    "# Tannenbaum point 1.\n",
    "Concerning the first aim of the Tannenbaum paper, the wallet report rates validate the survey measures of social capital. Similarly, the PISA education measure could be considered to validate the survey measures. This is probably already shown in some literature, somewhere. Although, it's interesting that the relationship between PISA scores and survey measures are very similar to wallet report rates relationship to survey measures.\n",
    "\n",
    "But I was very surprised to see that reading scores were strongly correlated with wallet reporting rates (rho = 0.78). Show plot of wallet v pisa. This is greater than any of the other \"Economic and Institutional Performance\" measures. It is generally striking that measurements of honesty are so closely correlated with educational outcomes. Takeaways/thoughts:\n",
    "- Both honesty and education are hard to influence but it's practically impossible for governments to move the needle on honesty. This gives credence to the notion that families and communities are what really influence educational outcomes.\n",
    "- Wallet report rates are a direct measure of social capital but not really a measure of \"Economic and Institutional Performance\" per se. And the measures that are presented in the second part of the paper and measures of economic and institutional performance but not direct measures of social capital. Education outcomes are definitely and measure of institutional performance but if it's super closely correlated with wallet report rates, there's some evidence that it's also a direct measure of social capital.\n",
    "\n",
    "# Tannenbaum point 2.\n",
    "There are four measures of \"Economic and Institutional Performance\" in the second part of the paper: GDP per capita (log_gdp), productivity(log_tfp), government effectiveness (gee), and letter grade efficiency (letter_grading). If PISA scores are considered a fifth measure of the same sort, we find that wallet reporting rates are an even more effective predictor. When combined with any other measure of social capital, the coefficient for wallet reporting rates are always statistically significant with p<0.01 and with R^2 greater than most of the other fit models. In fact, I suspect that for the single variable models (PISA ~ wallet_rate + C), that the R^2 is greater than for any of the other measures. I'm not sure why those regression results aren't in the paper.\n",
    "\n",
    "# Machine Learning to predict wallet response given predictors.\n",
    "I used all the variables I had access to: the experiment variables, the survey measures, the economic/institutional performance measures, the PISA scores. I couldn't get anything to yield a better accuracy than about 0.687. This makes sense because it would be crazy if you could actually predict how honest someone would be at any given time with such little information, particularly information about someone's past.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
